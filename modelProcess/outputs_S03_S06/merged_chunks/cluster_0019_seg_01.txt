美国国家标准与技术研究院(NIST)希望您——是的,就是您!——对其本周发布的《网络安全框架2.0》草案发表评论。作为对该框架的一次“重大更新”,该草案扩大了范围,增加了第六个功能“治理”,并通过修订指南简化了实施。例如,该框架最初专门针对保护美国关键基础设施组织,但现在旨在涵盖全球所有类型的组织,无论其规模、类型和行业领域。与此同时,新增的“治理”功能旨在解决风险管理策略、组织背景、网络安全供应链风险管理以及政策、流程和程序等领域的问题。其他五个功能包括:识别,专注于评估组织的网络风险;保护,关于采取措施防止和减少网络风险;检测,集中于发现和分析网络攻击和泄露;响应,致力于在网络事件发生后采取行动;恢复,专注于受影响资产和运营的恢复。“NIST网络安全框架(Framework或CSF)2.0提供了减少网络安全风险的指导,帮助组织理解和评估这些风险,确定优先级并沟通降低这些风险的行动,”草案文件写道。想与NIST分享您对这个CSF 2.0草案的反馈吗?您可以发送电子邮件至[email protected],直到2023年11月4日。NIST特别希望了解公众是否认为该草案解决了当前和预期的网络安全挑战,并符合既定的做法和指南。NIST预计将在2024年初发布CSF 2.0的最终版本,届时它将正式取代2018年发布的CSF 1.1。要获取更多详情,请查看CSF的主页,NIST的公告,一个草案摘要和完整的52页草案文件。
您的组织是否使用从公共存储库中提取的人工智能模型?您确定它是安全的吗?如果不确定,您可能需要查看一款新的免费开源工具,该工具旨在标记公共可用AI模型中的供应链漏洞和风险。这款名为AI风险数据库的工具由AI供应商Robust Intelligence于今年3月创建,并与MITRE合作进一步完善,本周在GitHub上发布了最新版本。印第安纳大学也参与了此次合作。“这次合作和AI风险数据库的发布可以直接使更多组织看到自己在部署特定类型的AI系统时面临的风险和脆弱性,”MITRE工程和原型设计副总裁Douglas Robbins在一份声明中表示。来自这三个组织的代表在拉斯维加斯举行的Black Hat USA 2023会议上进行了两次演讲。要获取更多详情,请查看MITRE和Robust Intelligence的公告。
弱密码或无密码,以及泄露的凭证占Google Cloud事件响应团队在2023年第一季度观察到的云安全漏洞的约62%。受到这一“持续挑战”影响的企业可以通过加强其身份管理工具和流程来解决这个问题,Google在其网络安全行动团队发布的“2023年8月威胁地平线报告”中表示。这份31页报告的其他发现包括:网络犯罪分子正在让看起来合法的Android应用程序通过Google Play商店的审核,然后通过未经批准的渠道进行隐蔽的版本更新,为其添加恶意功能。企业对此类威胁的缓解措施包括采用企业移动管理系统为用户创建预批准的应用程序列表。根据对Google Chronicle Security Operations匿名警报统计数据的分析,导致妥协的最大风险行为是跨项目滥用Google Cloud Platform的访问令牌生成权限。要获取所有详细信息,请阅读完整报告。
美国网络安全和基础设施安全局(CISA)希望通过其新发布的网络安全战略计划使网络安全漏洞变得罕见、组织能够抵御网络攻击、技术产品本质上是安全的。这些目标目前尚未实现,但CISA希望通过其计划在未来三年内达成。“我们必须清楚地认识到我们所追求的未来,在这个未来中,破坏性的网络入侵是一种令人震惊的异常现象,组织是安全且有弹性的,技术产品默认是安全的,”文件中写道。该计划确立了三个主要目标:应对直接威胁、加固阵地和大规模推动安全。要获取所有详细信息,请查看CISA的公告和完整计划文档。
被生成式 AI 的潜力所吸引,许多组织纷纷投身其中,却忽视了其潜在的陷阱。此外,还存在一种常见的漏洞,它会使 Web 应用程序数据面临风险。去年许多零日漏洞都是已知漏洞的变种,这一点也值得我们关注。了解当前数据泄露的成本——这确实非常昂贵!以下是截至8月4日一周内最值得关注的六件事。

企业拥抱生成式 AI,但忽视安全和合规风险。2023年可以说是工作场所中使用 AI 的“危险生活”之年。各行各业的各种规模的企业都在寻求变革性的好处,因此开始使用像 ChatGPT 这样的生成式 AI 工具。然而,大多数企业对这种技术在网络安全和合规性方面的风险视而不见。根据麦肯锡公司的调查,三分之一的受访者表示,他们的组织正在定期将生成式 AI 用于至少一项业务功能,主要是在营销/销售、产品开发和服务运营中。但大多数生成式 AI 的早期采用者都忽视了这些工具的风险。例如,只有21%的受访组织制定了员工使用生成式 AI 的政策。仅有38%的组织正在积极缓解网络安全风险,而对于监管合规风险,这一比例更低,仅为28%。该调查涵盖了1,684个组织,其中有913个组织在至少一项业务功能中使用了 AI。在使用 AI 的组织中,60%使用的是生成式 AI。