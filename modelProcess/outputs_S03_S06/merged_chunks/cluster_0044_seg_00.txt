您的组织是否使用从公共存储库中提取的人工智能模型?您确定它是安全的吗?如果不确定,您可能需要查看一款新的免费开源工具,该工具旨在标记公共可用AI模型中的供应链漏洞和风险。这款名为AI风险数据库的工具由AI供应商Robust Intelligence于今年3月创建,并与MITRE合作进一步完善,本周在GitHub上发布了最新版本。印第安纳大学也参与了此次合作。“这次合作和AI风险数据库的发布可以直接使更多组织看到自己在部署特定类型的AI系统时面临的风险和脆弱性,”MITRE工程和原型设计副总裁Douglas Robbins在一份声明中表示。来自这三个组织的代表在拉斯维加斯举行的Black Hat USA 2023会议上进行了两次演讲。要获取更多详情,请查看MITRE和Robust Intelligence的公告。
弱密码或无密码,以及泄露的凭证占Google Cloud事件响应团队在2023年第一季度观察到的云安全漏洞的约62%。受到这一“持续挑战”影响的企业可以通过加强其身份管理工具和流程来解决这个问题,Google在其网络安全行动团队发布的“2023年8月威胁地平线报告”中表示。这份31页报告的其他发现包括:网络犯罪分子正在让看起来合法的Android应用程序通过Google Play商店的审核,然后通过未经批准的渠道进行隐蔽的版本更新,为其添加恶意功能。企业对此类威胁的缓解措施包括采用企业移动管理系统为用户创建预批准的应用程序列表。根据对Google Chronicle Security Operations匿名警报统计数据的分析,导致妥协的最大风险行为是跨项目滥用Google Cloud Platform的访问令牌生成权限。要获取所有详细信息,请阅读完整报告。
美国网络安全和基础设施安全局(CISA)希望通过其新发布的网络安全战略计划使网络安全漏洞变得罕见、组织能够抵御网络攻击、技术产品本质上是安全的。这些目标目前尚未实现,但CISA希望通过其计划在未来三年内达成。“我们必须清楚地认识到我们所追求的未来,在这个未来中,破坏性的网络入侵是一种令人震惊的异常现象,组织是安全且有弹性的,技术产品默认是安全的,”文件中写道。该计划确立了三个主要目标:应对直接威胁、加固阵地和大规模推动安全。要获取所有详细信息,请查看CISA的公告和完整计划文档。
被生成式 AI 的潜力所吸引,许多组织纷纷投身其中,却忽视了其潜在的陷阱。此外,还存在一种常见的漏洞,它会使 Web 应用程序数据面临风险。去年许多零日漏洞都是已知漏洞的变种,这一点也值得我们关注。了解当前数据泄露的成本——这确实非常昂贵!以下是截至8月4日一周内最值得关注的六件事。

企业拥抱生成式 AI,但忽视安全和合规风险。2023年可以说是工作场所中使用 AI 的“危险生活”之年。各行各业的各种规模的企业都在寻求变革性的好处,因此开始使用像 ChatGPT 这样的生成式 AI 工具。然而,大多数企业对这种技术在网络安全和合规性方面的风险视而不见。根据麦肯锡公司的调查,三分之一的受访者表示,他们的组织正在定期将生成式 AI 用于至少一项业务功能,主要是在营销/销售、产品开发和服务运营中。但大多数生成式 AI 的早期采用者都忽视了这些工具的风险。例如,只有21%的受访组织制定了员工使用生成式 AI 的政策。仅有38%的组织正在积极缓解网络安全风险,而对于监管合规风险,这一比例更低,仅为28%。该调查涵盖了1,684个组织,其中有913个组织在至少一项业务功能中使用了 AI。在使用 AI 的组织中,60%使用的是生成式 AI。