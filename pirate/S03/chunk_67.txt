虽然大多数网络安全漏洞涉及技术问题，但网络安全最终还是一个人的问题。人为因素使企业面临风险，削弱了技术的有效性，但也可以弥补技术无法解决的问题。一些网络问题最好通过人性化解决方案或至少考虑人的状况来处理。我们分享了一些组织可以实施的专业提示，以减轻安全漏洞。这将有助于缓解网络安全计划中许多层级的工作量和压力
更多专业提示，请下载我们的信息图

寻找暴露的杂项错误
根据Verizon DBIR 2019报告，“杂项错误”是金融、保险、教育、医疗保健、信息、公共管理、零售和技术服务领域前三大违规模式之一。专业提示：只有冗余的、主动的流程才能解决这些人为造成的症状。您的员工应维护并寻求“错误”Top 10/25/100列表，并与同行合作维护这些列表。优先处理高影响漏洞。寻找方法进行隔离以减少暴露

依赖专家进行渗透测试，而不是冒牌货
人们倾向于熟悉和舒适的事物。一些渗透测试人员从同一个技巧袋中抽取，而不是系统地针对整个可能的风险范围。许多企业难以区分专家和冒牌货。专业提示：利用威胁框架，如Mitre Att@ck。选择威胁情报提供商时，部分应基于他们如何从可能性缩小到可能性。除非确定其非常出色，否则避免使用同一家渗透测试公司。不同渗透测试人员之间的差异可能很大，一个可能发现其他人遗漏的漏洞。了解AppGuard如何与关键网络安全框架对齐，请参阅我们的最新白皮书

构建基于角色的网络安全培训计划
有效的员工网络安全准备培训可以减轻主要风险。给接待员和IT系统管理员提供相同的培训可能比不培训更糟糕。他们对风险（太低）和缓解措施（太高）的看法差异很大。集中培训很快会被遗忘，警惕性的暂时提高会回到粗心大意的状态。人的问题需要人的解决方案。专业提示：个性化员工网络安全准备培训。通过模拟钓鱼等手段挖掘数据，找出高风险员工。使用针对不同角色定制的内容。使准备成为一个持续的过程，教导、激励并强化

由于COVID-19危机，大多数员工预计将在传统环境之外工作。此外，随着远程工作因各种原因成为常态，组织可以利用这个机会建立适合传统和远程环境的强大网络安全态势。重要的一点是，网络安全挑战不仅涉及技术，而且以人为本的解决方案也是必不可少的。适用于一个组织的最佳方案可能并不适合其他组织
被生成式 AI 的潜力所吸引，许多组织纷纷投身其中，却忽视了其潜在的陷阱。此外，还存在一种常见的漏洞，它会使 Web 应用程序数据面临风险。去年许多零日漏洞都是已知漏洞的变种，这一点也值得我们关注。了解当前数据泄露的成本——这确实非常昂贵！以下是截至8月4日一周内最值得关注的六件事。

企业拥抱生成式 AI，但忽视安全和合规风险。2023年可以说是工作场所中使用 AI 的“危险生活”之年。各行各业的各种规模的企业都在寻求变革性的好处，因此开始使用像 ChatGPT 这样的生成式 AI 工具。然而，大多数企业对这种技术在网络安全和合规性方面的风险视而不见。根据麦肯锡公司的调查，三分之一的受访者表示，他们的组织正在定期将生成式 AI 用于至少一项业务功能，主要是在营销/销售、产品开发和服务运营中。但大多数生成式 AI 的早期采用者都忽视了这些工具的风险。例如，只有21%的受访组织制定了员工使用生成式 AI 的政策。仅有38%的组织正在积极缓解网络安全风险，而对于监管合规风险，这一比例更低，仅为28%。该调查涵盖了1,684个组织，其中有913个组织在至少一项业务功能中使用了 AI。在使用 AI 的组织中，60%使用的是生成式 AI。

警惕一种常见的 Web 应用程序漏洞，它会使数据面临风险。美国和澳大利亚的网络安全机构警告称，有一种称为不安全直接对象引用 (IDOR) 漏洞的常见安全漏洞，恶意行为者利用它来篡改 Web 应用程序数据。这种访问控制缺陷会导致 Web 应用程序执行不足的身份验证和授权检查。当成功利用时，IDOR 漏洞允许黑客通过使用合法用户的标识符向网站或 Web API 发送请求来修改、删除和访问数据。澳大利亚网络安全中心 (ACSC)、美国网络安全和基础设施安全局 (CISA) 和美国国家安全局 (NSA) 在联合公告中写道：“这些漏洞经常被恶意行为者在数据泄露事件中利用，因为它们很常见，在开发过程之外很难预防，并且可以大规模滥用。”该文件描述了 IDOR 漏洞，解释了它们可能被利用的方式，并详细说明了针对 Web 应用程序供应商、设计师、开发者和最终用户的缓解措施。推荐的缓解措施包括：实施默认安全和设计安全原则，确保 Web 应用程序对每个修改、删除和访问数据的请求进行身份验证和授权检查，使用自动化代码审查工具发现并修复 IDOR 漏洞，不在 URL 上暴露 ID、名称和密钥，而是用密码学上强健的随机值替换它们。对于最终用户，建议进行安全尽职调查，尽快修补 Web 应用程序，并对其 Web 应用程序进行漏洞扫描和渗透测试。
您的组织是否使用从公共存储库中提取的人工智能模型？您确定它是安全的吗？如果不确定，您可能需要查看一款新的免费开源工具，该工具旨在标记公共可用AI模型中的供应链漏洞和风险。这款名为AI风险数据库的工具由AI供应商Robust Intelligence于今年3月创建，并与MITRE合作进一步完善，本周在GitHub上发布了最新版本。印第安纳大学也参与了此次合作。“这次合作和AI风险数据库的发布可以直接使更多组织看到自己在部署特定类型的AI系统时面临的风险和脆弱性，”MITRE工程和原型设计副总裁Douglas Robbins在一份声明中表示。来自这三个组织的代表在拉斯维加斯举行的Black Hat USA 2023会议上进行了两次演讲。要获取更多详情，请查看MITRE和Robust Intelligence的公告。
弱密码或无密码，以及泄露的凭证占Google Cloud事件响应团队在2023年第一季度观察到的云安全漏洞的约62%。受到这一“持续挑战”影响的企业可以通过加强其身份管理工具和流程来解决这个问题，Google在其网络安全行动团队发布的“2023年8月威胁地平线报告”中表示。这份31页报告的其他发现包括：网络犯罪分子正在让看起来合法的Android应用程序通过Google Play商店的审核，然后通过未经批准的渠道进行隐蔽的版本更新，为其添加恶意功能。企业对此类威胁的缓解措施包括采用企业移动管理系统为用户创建预批准的应用程序列表。根据对Google Chronicle Security Operations匿名警报统计数据的分析，导致妥协的最大风险行为是跨项目滥用Google Cloud Platform的访问令牌生成权限。要获取所有详细信息，请阅读完整报告。
美国网络安全和基础设施安全局（CISA）希望通过其新发布的网络安全战略计划使网络安全漏洞变得罕见、组织能够抵御网络攻击、技术产品本质上是安全的。这些目标目前尚未实现，但CISA希望通过其计划在未来三年内达成。“我们必须清楚地认识到我们所追求的未来，在这个未来中，破坏性的网络入侵是一种令人震惊的异常现象，组织是安全且有弹性的，技术产品默认是安全的，”文件中写道。该计划确立了三个主要目标：应对直接威胁、加固阵地和大规模推动安全。要获取所有详细信息，请查看CISA的公告和完整计划文档。