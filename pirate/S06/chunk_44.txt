有一个关于基于AI的网络安全产品的想法？你可以在一个新的竞赛中赢得数百万美元。同时，NIST已经起草了CSF 2.0的重大修订，并希望听取您的意见。此外，还有一个新的免费工具可以标记公共AI模型中的安全漏洞。另外，大多数云安全漏洞是由凭证错误引起的。还有更多内容！深入了解截至8月11日这一周最值得关注的六件事。

白宫和国防高级研究计划局（DARPA）本周公布了一项为期两年、奖金约2000万美元的竞赛，旨在促进基于AI的网络安全产品的发展。在拉斯维加斯举行的Black Hat USA 2023会议上宣布的人工智能网络挑战赛（AIxCC）吸引了计算机科学家、AI专家、软件开发人员和网络安全大师参与。AI供应商Anthropic、Google、Microsoft和OpenAI将通过提供其技术和专业知识来支持参与者，而开源安全基金会（OpenSSF）将担任顾问。小企业可以通过“资助赛道”参与，该赛道将为七家中小企业提供资金支持。其他所有人均可通过“公开赛道”参加。提交提案后，最多将有20个团队被选中参加2024年8月在DefCon举行的半决赛。得分最高的五个团队将获得奖金，并进入2025年8月在DefCon举行的决赛。“如果成功，AIxCC不仅会产生下一代网络安全工具，还将展示如何使用AI通过保护其关键基础设施来更好地服务于社会，”DARPA的AIxCC项目经理Perri Adams在一份声明中表示。要获取更多详情，请查看白宫的公告，DARPA的公告，OpenSSF的公告和AIxCC网站。

美国国家标准与技术研究院（NIST）希望您——是的，就是您！——对其本周发布的《网络安全框架2.0》草案发表评论。作为对该框架的一次“重大更新”，该草案扩大了范围，增加了第六个功能“治理”，并通过修订指南简化了实施。例如，该框架最初专门针对保护美国关键基础设施组织，但现在旨在涵盖全球所有类型的组织，无论其规模、类型和行业领域。与此同时，新增的“治理”功能旨在解决风险管理策略、组织背景、网络安全供应链风险管理以及政策、流程和程序等领域的问题。其他五个功能包括：识别，专注于评估组织的网络风险；保护，关于采取措施防止和减少网络风险；检测，集中于发现和分析网络攻击和泄露；响应，致力于在网络事件发生后采取行动；恢复，专注于受影响资产和运营的恢复。“NIST网络安全框架（Framework或CSF）2.0提供了减少网络安全风险的指导，帮助组织理解和评估这些风险，确定优先级并沟通降低这些风险的行动，”草案文件写道。想与NIST分享您对这个CSF 2.0草案的反馈吗？您可以发送电子邮件至[email protected]，直到2023年11月4日。NIST特别希望了解公众是否认为该草案解决了当前和预期的网络安全挑战，并符合既定的做法和指南。NIST预计将在2024年初发布CSF 2.0的最终版本，届时它将正式取代2018年发布的CSF 1.1。要获取更多详情，请查看CSF的主页，NIST的公告，一个草案摘要和完整的52页草案文件。
您的组织是否使用从公共存储库中提取的人工智能模型？您确定它是安全的吗？如果不确定，您可能需要查看一款新的免费开源工具，该工具旨在标记公共可用AI模型中的供应链漏洞和风险。这款名为AI风险数据库的工具由AI供应商Robust Intelligence于今年3月创建，并与MITRE合作进一步完善，本周在GitHub上发布了最新版本。印第安纳大学也参与了此次合作。“这次合作和AI风险数据库的发布可以直接使更多组织看到自己在部署特定类型的AI系统时面临的风险和脆弱性，”MITRE工程和原型设计副总裁Douglas Robbins在一份声明中表示。来自这三个组织的代表在拉斯维加斯举行的Black Hat USA 2023会议上进行了两次演讲。要获取更多详情，请查看MITRE和Robust Intelligence的公告。
弱密码或无密码，以及泄露的凭证占Google Cloud事件响应团队在2023年第一季度观察到的云安全漏洞的约62%。受到这一“持续挑战”影响的企业可以通过加强其身份管理工具和流程来解决这个问题，Google在其网络安全行动团队发布的“2023年8月威胁地平线报告”中表示。这份31页报告的其他发现包括：网络犯罪分子正在让看起来合法的Android应用程序通过Google Play商店的审核，然后通过未经批准的渠道进行隐蔽的版本更新，为其添加恶意功能。企业对此类威胁的缓解措施包括采用企业移动管理系统为用户创建预批准的应用程序列表。根据对Google Chronicle Security Operations匿名警报统计数据的分析，导致妥协的最大风险行为是跨项目滥用Google Cloud Platform的访问令牌生成权限。要获取所有详细信息，请阅读完整报告。
美国网络安全和基础设施安全局（CISA）希望通过其新发布的网络安全战略计划使网络安全漏洞变得罕见、组织能够抵御网络攻击、技术产品本质上是安全的。这些目标目前尚未实现，但CISA希望通过其计划在未来三年内达成。“我们必须清楚地认识到我们所追求的未来，在这个未来中，破坏性的网络入侵是一种令人震惊的异常现象，组织是安全且有弹性的，技术产品默认是安全的，”文件中写道。该计划确立了三个主要目标：应对直接威胁、加固阵地和大规模推动安全。要获取所有详细信息，请查看CISA的公告和完整计划文档。
被生成式 AI 的潜力所吸引，许多组织纷纷投身其中，却忽视了其潜在的陷阱。此外，还存在一种常见的漏洞，它会使 Web 应用程序数据面临风险。去年许多零日漏洞都是已知漏洞的变种，这一点也值得我们关注。了解当前数据泄露的成本——这确实非常昂贵！以下是截至8月4日一周内最值得关注的六件事。

企业拥抱生成式 AI，但忽视安全和合规风险。2023年可以说是工作场所中使用 AI 的“危险生活”之年。各行各业的各种规模的企业都在寻求变革性的好处，因此开始使用像 ChatGPT 这样的生成式 AI 工具。然而，大多数企业对这种技术在网络安全和合规性方面的风险视而不见。根据麦肯锡公司的调查，三分之一的受访者表示，他们的组织正在定期将生成式 AI 用于至少一项业务功能，主要是在营销/销售、产品开发和服务运营中。但大多数生成式 AI 的早期采用者都忽视了这些工具的风险。例如，只有21%的受访组织制定了员工使用生成式 AI 的政策。仅有38%的组织正在积极缓解网络安全风险，而对于监管合规风险，这一比例更低，仅为28%。该调查涵盖了1,684个组织，其中有913个组织在至少一项业务功能中使用了 AI。在使用 AI 的组织中，60%使用的是生成式 AI。

警惕一种常见的 Web 应用程序漏洞，它会使数据面临风险。美国和澳大利亚的网络安全机构警告称，有一种称为不安全直接对象引用 (IDOR) 漏洞的常见安全漏洞，恶意行为者利用它来篡改 Web 应用程序数据。这种访问控制缺陷会导致 Web 应用程序执行不足的身份验证和授权检查。当成功利用时，IDOR 漏洞允许黑客通过使用合法用户的标识符向网站或 Web API 发送请求来修改、删除和访问数据。澳大利亚网络安全中心 (ACSC)、美国网络安全和基础设施安全局 (CISA) 和美国国家安全局 (NSA) 在联合公告中写道：“这些漏洞经常被恶意行为者在数据泄露事件中利用，因为它们很常见，在开发过程之外很难预防，并且可以大规模滥用。”该文件描述了 IDOR 漏洞，解释了它们可能被利用的方式，并详细说明了针对 Web 应用程序供应商、设计师、开发者和最终用户的缓解措施。推荐的缓解措施包括：实施默认安全和设计安全原则，确保 Web 应用程序对每个修改、删除和访问数据的请求进行身份验证和授权检查，使用自动化代码审查工具发现并修复 IDOR 漏洞，不在 URL 上暴露 ID、名称和密钥，而是用密码学上强健的随机值替换它们。对于最终用户，建议进行安全尽职调查，尽快修补 Web 应用程序，并对其 Web 应用程序进行漏洞扫描和渗透测试。